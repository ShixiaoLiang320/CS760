{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "87840df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/10/wvdf743d5ms1hmr269llqccc0000gn/T/ipykernel_46787/1564087039.py:9: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-z))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.931, 'precision': 0.8913043478257641, 'recall': 0.8631578947365393}\n",
      "Fold 2\n",
      "{'accuracy': 0.935, 'precision': 0.9015151515148101, 'recall': 0.859205776172975}\n",
      "Fold 3\n",
      "{'accuracy': 0.916, 'precision': 0.9273504273500311, 'recall': 0.7640845070419845}\n",
      "Fold 4\n",
      "{'accuracy': 0.926, 'precision': 0.892857142856824, 'recall': 0.8503401360541326}\n",
      "Fold 5\n",
      "{'accuracy': 0.904, 'precision': 0.8431372549016852, 'recall': 0.8431372549016852}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv('emails.csv')\n",
    "data = data.drop(columns=['Email No.'])\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def report(y_true, y_pred):\n",
    "    accuracy = np.mean(y_true == y_pred)\n",
    "    true_positives = np.sum((y_pred == 1) & (y_true == 1))\n",
    "    predicted_positives = np.sum(y_pred == 1)\n",
    "    actual_positives = np.sum(y_true == 1)\n",
    "    \n",
    "    precision = true_positives / (predicted_positives + 1e-10)\n",
    "    recall = true_positives / (actual_positives + 1e-10)\n",
    "    \n",
    "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall}\n",
    "\n",
    "def LogisticRegression(train: pd.DataFrame, test: pd.DataFrame, lr: float, iterations: int):\n",
    "    trainX = train.iloc[:, :-1].values\n",
    "    trainY = train.iloc[:, -1].values\n",
    "    testX = test.iloc[:, :-1].values\n",
    "    testY = test.iloc[:, -1].values\n",
    "\n",
    "    theta = np.zeros(trainX.shape[1])\n",
    "\n",
    "    for i in range(iterations):\n",
    "        z = np.dot(trainX, theta)\n",
    "        y_hat = sigmoid(z)\n",
    "        gradient = np.dot(trainX.T, (y_hat - trainY)) / len(y_hat)\n",
    "        theta -= lr * gradient\n",
    "\n",
    "    predictions = (sigmoid(np.dot(testX, theta)) >= 0.5).astype(int)\n",
    "    return report(testY, predictions)\n",
    "\n",
    "k = 5\n",
    "fold_size = len(data) // k\n",
    "\n",
    "for fold in range(k):\n",
    "    start_idx = fold * fold_size\n",
    "    end_idx = (fold + 1) * fold_size if fold != k - 1 else len(data)\n",
    "    \n",
    "    test_data = data.iloc[start_idx:end_idx, :]\n",
    "    train_data = data.drop(data.index[start_idx:end_idx])\n",
    "    \n",
    "    print(f\"Fold {fold + 1}\")\n",
    "    results = LogisticRegression(train_data, test_data, lr=0.01, iterations=3000)\n",
    "    print(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b708ce2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
